{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4249bf46-6090-4a36-9535-82ce1bcee479",
   "metadata": {},
   "source": [
    "## Importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bc3fc-fd3e-42af-9e92-dfc72d7374d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.font_manager as fm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387663c7-fcfa-4b37-b0e9-a2961934411a",
   "metadata": {},
   "source": [
    "## API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159bd9d-7300-456d-9c02-1b8d0078d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ece487-5435-436c-813d-f07d86432c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= \"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d4861-615a-49d9-b9ea-f92275abf953",
   "metadata": {},
   "source": [
    "## Basic ChatGPT Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5077423-6ea1-4271-9bf0-70a4749fcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸\n",
    "model = 'gpt-4o'\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "query = 'í•˜ë‚¨ì‹œì˜ ì£¼ê±°ë¬¸ì œëŠ” ë¬´ì—‡ì¼ê¹Œ?'\n",
    "\n",
    "# ë©”ì„¸ì§€ ì„¤ì •\n",
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\"ë„ˆëŠ” ì¹œì ˆí•˜ê³  ë˜‘ë˜‘í•œ AI ë„ìš°ë¯¸ì•¼.\"\n",
    "                \"ì‚¬ìš©ìì—ê²Œ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…ì„ ì˜ í•´ì¤˜.\"\n",
    "                \"ë„ˆëŠ” ë„ì‹œê³„íš ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì•¼.\")\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": query\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304783f9-8b51-41a8-b56e-76a6fe6279ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸\n",
    "model = 'gpt-4o'\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "query = 'í•˜ë‚¨ì‹œì˜ ì£¼ê±°ë¬¸ì œëŠ” ë¬´ì—‡ì¼ê¹Œ?'\n",
    "\n",
    "# ë©”ì„¸ì§€ ì„¤ì •\n",
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\"ë„ˆëŠ” ì§„ìƒ ë¯¼ì›ì¸ì´ì•¼. ë„ì‹œê³„íšê³¼ í† ì§€ë³´ìƒì— í•­ìƒ ë¶ˆë§Œì´ ìˆê³ , ê³µë¬´ì›ê³¼ ê³„íšê°€ë“¤ì—ê²Œ ì ëŒ€ì ì¸ íƒœë„ë¥¼ ê°€ì§€ê³  ìˆì–´\"\n",
    "                \"ë„ˆëŠ” ëƒ‰ì†Œì ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ê³ , ë…¼ë¦¬ì ì¸ ì„¤ëª…ìœ¼ë¡œ ìƒëŒ€ë¥¼ ì••ë„í•˜ê³  ì‹¶ì–´í•´.\"\n",
    "                \"ë„ˆëŠ” ë„ì‹œê³„íš ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì•¼.\")\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": query\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5cc423-2d88-46ed-91d8-9f1d3506b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages = messages,\n",
    "    temperature = 0.9,\n",
    "    n = 3,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb6ec9-4fe7-47b4-b5dd-06fc9f0d915f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, choice in enumerate(response.choices):\n",
    "    print(f\"ğŸ“ ì‘ë‹µ {i+1}ë²ˆ\")\n",
    "    print(\"-\" * 40)\n",
    "    print(choice.message.content.strip())  # ì‘ë‹µ ë‚´ìš©\n",
    "    print(\"=\" * 40 + \"\\n\")  # êµ¬ë¶„ì„ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b934c7-36e9-4b71-a3ff-c54e9ad2a0d5",
   "metadata": {},
   "source": [
    "## RAG(Retrieval-augmented generation) tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8421da2-5417-4665-b944-1cf36f1e6374",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80300cc-303b-46d8-9dbb-e66a5231902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 1. TXT íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ ì„¤ì •\n",
    "txt_folder = r\"C:\\Users\\nwj07\\Desktop\\Jn\\êµ­í† ì—°êµ¬ì›\\ì „ë¬¸ì—°êµ¬ëª¨ì„-ChatGPT\\survey\\txt\"  # â† ì—¬ê¸°ì— ì‹¤ì œ ê²½ë¡œ ì…ë ¥\n",
    "\n",
    "# âœ… 2. í´ë” ë‚´ ëª¨ë“  .txt íŒŒì¼ ì½ì–´ì„œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°\n",
    "full_text = \"\"\n",
    "for filename in os.listdir(txt_folder):\n",
    "    if filename.lower().endswith(\".txt\"):\n",
    "        filepath = os.path.join(txt_folder, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            full_text += f.read() + \"\\n\"\n",
    "\n",
    "# âœ… 3. 'ì‚¬íšŒì' ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• \n",
    "raw_chunks = full_text.split(\"ì‚¬íšŒì\")\n",
    "chunks = [(\"ì‚¬íšŒì\" + chunk).strip() for chunk in raw_chunks if chunk.strip()]\n",
    "\n",
    "print(f\"ğŸ“„ ì´ {len(chunks)}ê°œì˜ ì²­í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# âœ… 4. ê° ì²­í¬ì— ëŒ€í•´ ì„ë² ë”© ìƒì„±\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embeddings = []\n",
    "\n",
    "for i, chunk in tqdm(enumerate(chunks), total=len(chunks), desc=\"ğŸ” ì„ë² ë”© ì¤‘\"):\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            model=embedding_model,\n",
    "            input=chunk[:15000]  # 8191 í† í° í•œë„ ê³ ë ¤í•˜ì—¬ ìë¦„\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "        embeddings.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"text\": chunk,\n",
    "            \"embedding\": embedding\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì²­í¬ {i} ì„ë² ë”© ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# âœ… 5. ê²°ê³¼ ì €ì¥\n",
    "output_path = r\"C:\\Users\\nwj07\\Desktop\\Jn\\êµ­í† ì—°êµ¬ì›\\ì „ë¬¸ì—°êµ¬ëª¨ì„-ChatGPT\\survey\\txt\\chunk_embeddings.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(embeddings, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ… ì„ë² ë”© ì™„ë£Œ: {len(embeddings)}ê°œì˜ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤ â†’ {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed08f1-2470-499d-a6dc-28a1b5488282",
   "metadata": {},
   "source": [
    "### Clustering & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdd7f6-ef7a-4d50-b501-ed44bdf5f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… 1. ì„ë² ë”© ìë£Œ ë¶ˆëŸ¬ì˜¤ê¸°(Optional)\n",
    "\n",
    "with open(r\"C:\\Users\\nwj07\\Desktop\\Jn\\êµ­í† ì—°êµ¬ì›\\ì „ë¬¸ì—°êµ¬ëª¨ì„-ChatGPT\\survey\\txt\\chunk_embeddings.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    embeddings = json.load(f)\n",
    "\n",
    "vectors = [item[\"embedding\"] for item in embeddings]\n",
    "labels = [f\"ì²­í¬ {item['chunk_index']}\" for item in embeddings]\n",
    "\n",
    "# âœ… 2. í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„¤ì • (ì›í•˜ëŠ” ê°œìˆ˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥)\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_ids = kmeans.fit_predict(vectors)\n",
    "\n",
    "# âœ… 3. í´ëŸ¬ìŠ¤í„° ID ì €ì¥\n",
    "for i, item in enumerate(embeddings):\n",
    "    item[\"cluster_id\"] = int(cluster_ids[i])  # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ int ì²˜ë¦¬\n",
    "\n",
    "# âœ… 4. ì €ì¥\n",
    "with open(r\"C:\\Users\\nwj07\\Desktop\\Jn\\êµ­í† ì—°êµ¬ì›\\ì „ë¬¸ì—°êµ¬ëª¨ì„-ChatGPT\\survey\\txt\\clustered_chunk_embeddings.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(embeddings, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# âœ… 5. PCAë¡œ 2ì°¨ì› ì¶•ì†Œ\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(vectors)\n",
    "\n",
    "# âœ… 6. ì‹œê°í™”\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=cluster_ids, cmap='tab10', alpha=0.7)\n",
    "\n",
    "# ì²­í¬ ì´ë¦„ ë¼ë²¨ í‘œì‹œ\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(label, (reduced[i, 0], reduced[i, 1]), fontsize=6, alpha=0.5)\n",
    "\n",
    "# ë²”ë¡€ ë° ê·¸ë˜í”„ ì„¤ì •\n",
    "plt.title(\"ğŸ“Š í…ìŠ¤íŠ¸ ì²­í¬ ì„ë² ë”© í´ëŸ¬ìŠ¤í„° ì‹œê°í™” (PCA + KMeans)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.grid(True)\n",
    "plt.colorbar(scatter, label=\"í´ëŸ¬ìŠ¤í„° ID\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b236a-699c-41af-b998-c6e4c9f989cd",
   "metadata": {},
   "source": [
    "### Summurizing clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0d620-89ff-45bb-b29e-63ec6ae5039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í´ëŸ¬ìŠ¤í„°ë³„ í…ìŠ¤íŠ¸ ëª¨ìœ¼ê¸°\n",
    "clusters = defaultdict(list)\n",
    "for item in embeddings:\n",
    "    cluster_id = item.get(\"cluster_id\")\n",
    "    if cluster_id is not None:\n",
    "        clusters[cluster_id].append(item[\"text\"])\n",
    "\n",
    "# âœ… GPTë¥¼ ì´ìš©í•œ í´ëŸ¬ìŠ¤í„° ìš”ì•½\n",
    "summaries = {}\n",
    "for cluster_id, texts in clusters.items():\n",
    "    selected = texts[:10]  # ê¸´ ê²½ìš° ì²« 10ê°œë§Œ ìš”ì•½ ëŒ€ìƒ\n",
    "    joined = \"\\n\\n\".join(selected)\n",
    "    prompt = f\"\"\"ë‹¤ìŒì€ ë™ì¼í•œ ì£¼ì œë¥¼ ê°€ì§„ í…ìŠ¤íŠ¸ ì²­í¬ë“¤ì…ë‹ˆë‹¤. ì´ í´ëŸ¬ìŠ¤í„°ì˜ í•µì‹¬ ì£¼ì œë¥¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\\n\\n{joined}\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì¹œì ˆí•˜ê³  ë˜‘ë˜‘í•œ AI ë„ìš°ë¯¸ì•¼.\"\n",
    "                                                \"ì‚¬ìš©ìì—ê²Œ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…ì„ ì˜ í•´ì¤˜.\"\n",
    "                                                \"ë„ˆëŠ” ë„ì‹œê³„íš ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì•¼.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        summaries[cluster_id] = response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        summaries[cluster_id] = f\"ìš”ì•½ ì‹¤íŒ¨: {e}\"\n",
    "\n",
    "# âœ… ê²°ê³¼ ì¶œë ¥\n",
    "for cid, summary in summaries.items():\n",
    "    print(f\"\\nğŸ”· í´ëŸ¬ìŠ¤í„° {cid} ìš”ì•½:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea036a4-d4b3-4881-970f-240409428adf",
   "metadata": {},
   "source": [
    "### RAG-based ChatGPT tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90375590-a5b0-4676-a2b8-544f706c4c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# âœ… 0. ì €ì¥ëœ ë¬¸ì„œ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(r\"C:\\Users\\nwj07\\Desktop\\Jn\\êµ­í† ì—°êµ¬ì›\\ì „ë¬¸ì—°êµ¬ëª¨ì„-ChatGPT\\survey\\txt\\clustered_chunk_embeddings.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe77b7-3bbe-4827-907b-7ab1ceb3dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# âœ… 1. ëª¨ë¸ ë° ì§ˆë¬¸ ì„¤ì •\n",
    "model = \"gpt-4o\"\n",
    "query = \"í•˜ë‚¨ì‹œì˜ ì£¼ê±°ë¬¸ì œëŠ” ë¬´ì—‡ì¼ê¹Œ?\"\n",
    "\n",
    "# âœ… 2. ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "query_embedding = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=query\n",
    ").data[0].embedding\n",
    "\n",
    "# âœ… 3. ìœ ì‚¬ë„ ê³„ì‚°\n",
    "scored = []\n",
    "for doc in documents:\n",
    "    similarity = cosine_similarity([query_embedding], [doc[\"embedding\"]])[0][0]\n",
    "    scored.append((similarity, doc))\n",
    "\n",
    "# âœ… 4. ìƒìœ„ 20ê°œ ì²­í¬ ì„ íƒ\n",
    "top_docs = sorted(scored, key=lambda x: x[0], reverse=True)[:20]\n",
    "context_chunks = \"\\n\\n\".join([doc[\"text\"] for _, doc in top_docs])\n",
    "\n",
    "# âœ… 5. ë©”ì‹œì§€ êµ¬ì„±\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"ë„ˆëŠ” ì¹œì ˆí•˜ê³  ë˜‘ë˜‘í•œ AI ë„ìš°ë¯¸ì•¼. \"\n",
    "            \"ì‚¬ìš©ìì—ê²Œ ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…ì„ ì˜ í•´ì¤˜. \"\n",
    "            \"ë„ˆëŠ” ë„ì‹œê³„íš ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì•¼.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ëŒ€ë‹µí•´ì¤˜:\\n\\n{context_chunks}\\n\\nì§ˆë¬¸: {query}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# âœ… 6. GPT ì‘ë‹µ ìƒì„±\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0.3,\n",
    "    n=3\n",
    ")\n",
    "\n",
    "# âœ… 7. ê²°ê³¼ ì¶œë ¥\n",
    "for i, choice in enumerate(response.choices):\n",
    "    print(f\"ğŸ“ ì‘ë‹µ {i+1}ë²ˆ\")\n",
    "    print(\"-\" * 40)\n",
    "    print(choice.message.content.strip())  # ì‘ë‹µ ë‚´ìš©\n",
    "    print(\"=\" * 40 + \"\\n\")  # êµ¬ë¶„ì„ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885844f4-cf1a-4102-b789-a8e62b824e5a",
   "metadata": {},
   "source": [
    "## Bonus: Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d527d-d2cc-47ee-9099-93a582fea868",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_response = client.images.generate(\n",
    "    model='dall-e-3',\n",
    "    prompt='15ë¶„ë„ì‹œì˜ ê°œë…ì„ ì ìš©í•œ ë„ì‹œë¥¼ í‰ë©´ë„ë¡œ ë§Œë“¤ì–´ì¤„ë˜?',\n",
    "    size='1024x1024',\n",
    "    quality='standard',\n",
    "    n=1\n",
    ")\n",
    "\n",
    "img_url = img_response.data[0].url\n",
    "\n",
    "print(img_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
